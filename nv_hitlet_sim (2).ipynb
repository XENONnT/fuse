{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2ee8d-3fb7-43ea-bcce-f5d9ab814143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas  as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b27b59-3e4f-4f89-9ff6-3f00be3df701",
   "metadata": {},
   "source": [
    "# Service functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db92cb-822d-4937-ae19-aa1649f03e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------\n",
    "# Retrieving PMT QE\n",
    "def _init_quantum_efficiency():\n",
    "    \"\"\"Loads and returns channel specific quantum efficiency values for\n",
    "    neutron-veto PMTs. Returns a dictionary containing interpolated \n",
    "    QE for each channel\n",
    "    \"\"\"\n",
    "    with open('nveto_pmt_qe.json', 'r') as f:\n",
    "    # Load the contents of the file as a Python object\n",
    "        nv_pmt_qe = json.load(f)\n",
    "    res = {}\n",
    "\n",
    "    wavelength = nv_pmt_qe['nv_pmt_qe_wavelength']\n",
    "    \n",
    "    for channel, qe in nv_pmt_qe['nv_pmt_qe'].items():\n",
    "        res[channel] = interp1d(wavelength,\n",
    "                                np.array(qe)/100, # QE-values in file are in percent...\n",
    "                                bounds_error=False,\n",
    "                                fill_value=0\n",
    "                               )\n",
    "    return res\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# SPE PDFs (currently reading SR1 spectra)\n",
    "def reading_pdf(x_data=\"x_data_per_channel.npy\", y_data=\"pdf_per_channel.npy\"):\n",
    "    x=np.load(x_data,allow_pickle=True)\n",
    "    y=np.load(y_data,allow_pickle=True)\n",
    "    return x, y\n",
    "\n",
    "x_interp, pdf_per_channel = reading_pdf(x_data=\"x_data_per_channel.npy\", y_data=\"pdf_per_channel.npy\")\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# SPE acceptance per PMT (SR0 values) #consider these just as a placeholder (SR1 values need to be calculated!)\n",
    "spe_acc=np.array([91.2,91.1,92.9,89.8,92.7,94.8,93.0,90.6,90.0,89.9,89.0,84.2,89.0,93.7,92.3,91.1,91.8,91.1,92.7,92.4,86.7,93.8,93.7,92.7,92.9,94.1,92.3,84.5,89.6,91.9,86.5,91.5,92.6,89.5,92.5,90.1,92.9,92.8,88.0,91.3,92.5,88.2,95.0,94.2,90.8,88.0,92.5,91.3,89.4,93.4,91.7,92.2,93.0,91.0,83.5,87.9,88.3,90.1,91.2,90.6,92.5,92.3,93.2,89.4,90.9,88.0,92.6,91.4,93.2,92.3,86.9,93.8,92.2,93.6,92.1,91.4,93.0,92.0,93.6,91.4,86.6,94.7,93.7,93.2,91.3,92.3,94.7,91.2,94.4,93.6,91.4,94.9,89.4,91.5,90.7,92.2,91.4,91.5,93.1,91.9,87.5,92.2,92.1,90.1,93.0,93.3,89.2,88.7,92.0,94.2,88.9,90.3,92.3,87.6,91.0,89.8,91.9,91.6,92.2,93.9])*10**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58a1ec-8196-4129-a6c5-120483a972e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------\n",
    "# Sampling charge from SPE spectra\n",
    "# old code; reading and drawing from CDFs\n",
    "\n",
    "'''\n",
    "def reading_cdf(data=\"cdf_sampling.npy\"):\n",
    "    y_cdf=np.load(data,allow_pickle=True)\n",
    "    return y_cdf\n",
    "\n",
    "y_cdfs=reading_cdf(data=\"cdf_sampling.npy\")\n",
    "# Indice -> Canale/PMT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def random_sampling_pdf(cdf,size=1):\n",
    "    \"\"\"\n",
    "    Random sampling based on custom PDF\n",
    "    x0   : x lower bound = 0\n",
    "    x1   : x upper bound = 3\n",
    "    pdf  : custom function normalized to 1\n",
    "    size : number of events to generate\n",
    "    \"\"\"\n",
    "    xi=np.arange(-100.,3,0.01)\n",
    "    samples=np.zeros(size)\n",
    "    for i in range(0,size):\n",
    "        values = np.random.rand()\n",
    "        value_bins = np.searchsorted(cdf, values)\n",
    "        sample=xi[value_bins]\n",
    "        samples[i]=sample    \n",
    "    return samples\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "def _draw_charge(pmts, n_draws, cdfs):\n",
    "    min_ch = 2000\n",
    "    max_ch = 2120\n",
    "    n_pmts = max_ch-min_ch+1\n",
    "    res = np.zeros((n_pmts, np.max(n_draws)), np.float32)\n",
    "\n",
    "    for ch, n_hits in zip(pmts, n_draws):\n",
    "        cdf = cdfs[ch-min_ch]\n",
    "        res[ch-min_ch][:n_hits] = random_sampling_pdf(cdf, n_hits)\n",
    "    return res\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391b0ee-adc1-4088-9d52-2f1562522a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------\n",
    "# Sampling charge from SPE spectra\n",
    "\n",
    "def _get_charge(pmthits, spe_pdfs,x_data):\n",
    "    \"\"\"Generates charge for each PMT hit. \n",
    "    :param pmthits: akward array containing the field \"pmthitID\"\n",
    "    :param spe_pdfs: SPE pdfs\n",
    "    \"\"\"\n",
    "    offsets = ak.num(pmthits['pmthitTime'])\n",
    "\n",
    "    pmthitids = ak.ravel(pmthits['pmthitID'])\n",
    "    pmts, n_hits = np.unique(pmthitids, return_counts=True)\n",
    "    charge = _draw_charge(pmts, n_hits, spe_pdfs,x_data)#cdfs)\n",
    "    pmtcharge = _map_charge(pmthitids, charge)\n",
    "\n",
    "    pmthits['pmthitCharge'] = ak.unflatten(pmtcharge, offsets)\n",
    "    return pmthits\n",
    "\n",
    "\n",
    "\n",
    "#Nuovo: con pdf invece di cdf\n",
    "def _draw_charge(pmts, n_draws, spe_pdfs,x_data):\n",
    "    n_pmts = 120\n",
    "    res = np.zeros((n_pmts,  \n",
    "                    np.max(n_draws)), np.float32)\n",
    "\n",
    "    for ch, n_hits in zip(pmts, n_draws):\n",
    "        \n",
    "        spe_pdf_channel = spe_pdfs[ch-2000]\n",
    "        x_data_channel = x_data[ch-2000]\n",
    "        res[ch-2000][:n_hits] = np.random.choice(x_data_channel, \n",
    "                                           n_hits,\n",
    "                                           p=spe_pdf_channel\n",
    "         )\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _map_charge(pmthitids, charge):\n",
    "    \"\"\"Function which maps drawn charge for each PMT into the correct \n",
    "    order.\n",
    "    \"\"\"\n",
    "    indicies = np.zeros(120, np.int64)\n",
    "    res = np.zeros(len(pmthitids), np.float32)\n",
    "    for ind, ch in enumerate(pmthitids):\n",
    "        ch -= 2000\n",
    "        _charge_in_hit = charge[ch][indicies[ch]] \n",
    "        if _charge_in_hit >=  0:\n",
    "            res[ind] = _charge_in_hit\n",
    "        indicies[ch] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3558f-4fb8-4dfe-961b-8ce247b102dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_truth( truth):\n",
    "    \"\"\"Funciton which stacks delta pulse hitlets if they occure in the \n",
    "    same channel at the same time.\n",
    "    \"\"\"\n",
    "    res = np.zeros(len(truth), dtype=truth.dtype)\n",
    "    return _stack_truth(truth, res)\n",
    "\n",
    "def _stack_truth(truth, res):\n",
    "    offset = -1\n",
    "    current_time = -1\n",
    "    current_channel = -1\n",
    "    for hit in truth:\n",
    "        _is_same_delta_hit = hit['time'] == current_time and hit['channel'] == current_channel\n",
    "        if _is_same_delta_hit:\n",
    "            continue\n",
    "        else:\n",
    "            offset += 1\n",
    "            res[offset]['time'] = hit['time']\n",
    "            res[offset]['channel'] = hit['channel']\n",
    "            res[offset]['save_flag'] = hit['save_flag']\n",
    "            res[offset]['event_starts'] = hit['event_starts']\n",
    "            res[offset]['e_pri'] = hit['e_pri']\n",
    "            current_time = hit['time']\n",
    "            current_channel = hit['channel']\n",
    "    return res[:(offset+1)]\n",
    "\n",
    "\n",
    "def get_mc_truth( pmthits, hitlets):\n",
    "        \"\"\"Function which can be replaced by the user to store custom\n",
    "        MC truth information for each hitlet. Takes awkward array \n",
    "        containing simulation information of each and the resulting \n",
    "        hitlet array.\n",
    "        \"\"\"\n",
    "        return np.zeros(0, dtype=strax.time_fields + ['channel', np.int16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d13902-fd4d-47aa-8dd9-bf9ef3d07ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------\n",
    "# Creating straxen hitlets and events\n",
    "\n",
    "import strax\n",
    "def pseudo_hitlet_dtype():\n",
    "    dtype = []\n",
    "    dtype += strax.time_dt_fields\n",
    "    dtype += [(('Psuedo hitlet area', 'area'), np.float32),\n",
    "              (('Psuedo hitlet channel', 'channel'), np.int16)\n",
    "             ]\n",
    "    return dtype\n",
    "\n",
    "def stack_hitlets(pseudo_hitlets):\n",
    "    \"\"\"Funciton which stacks delta pulse hitlets if they occure in the \n",
    "    same channel at the same time.\n",
    "    \"\"\"\n",
    "    res = np.zeros(len(pseudo_hitlets), dtype=pseudo_hitlet_dtype())\n",
    "    res['length'] = 1\n",
    "    res['dt'] = 1\n",
    "    return _stack_hitlets(pseudo_hitlets, res)\n",
    "\n",
    "def _stack_hitlets(pseudo_hitlets, res):\n",
    "    offset = -1\n",
    "    current_time = -1\n",
    "    current_channel = -1\n",
    "    for hit in pseudo_hitlets:\n",
    "        _is_same_delta_hit = hit['time'] == current_time and hit['channel'] == current_channel\n",
    "        if _is_same_delta_hit:\n",
    "            res[offset]['area'] += hit['area']\n",
    "        else:\n",
    "            offset += 1\n",
    "            res[offset]['time'] = hit['time']\n",
    "            res[offset]['channel'] = hit['channel']\n",
    "            res[offset]['area'] = hit['area']\n",
    "            current_time = hit['time']\n",
    "            current_channel = hit['channel']\n",
    "    return res[:(offset+1)]   \n",
    "\n",
    "def convert_to_hitlets(\n",
    "                       pmthits, \n",
    "                       source_rate=156,\n",
    "                       max_time=int(3600*24*7),\n",
    "                      ):\n",
    "    \"\"\"Function which converts GEANT4 output into pseudo hitlets. To \n",
    "    allow for pile-up draw event time stamps from a uniform distribution \n",
    "    mimicing the source rate.\n",
    "    :param pmthits: awkward array storing information about the PMT hits.\n",
    "    :param source_rate: Rate of the AmBe source in n/s.\n",
    "    :param max_time: Maximum time allowed for events. Currently it is \n",
    "        set to one week to account for longer lived isotopes during \n",
    "        calibration.\n",
    "    :returns: pseudo hitlets, mc_truth_extra_information\n",
    "    \"\"\"\n",
    "    n_events = len(pmthits['pmthitTime'])\n",
    "    offsets = ak.num(pmthits['pmthitTime'])\n",
    "    event_times = np.random.uniform(0, n_events/source_rate, n_events)\n",
    "    event_times *=10**9\n",
    "    event_times = event_times.astype(np.int64) \n",
    "    # Add some unix time (20220526 19:44= otherwise sorting does not \n",
    "    # work\n",
    "    event_times += np.int64(1653587233*10**9 )\n",
    "    pmthits['event_start_times'] = event_times\n",
    "    hit_times = pmthits['pmthitTime']*10**9 \n",
    "\n",
    "\n",
    "    hit_times = ak.to_numpy(ak.ravel(hit_times)).astype(np.int64)\n",
    "    event_times = np.repeat(event_times, offsets)\n",
    "    hit_times += event_times\n",
    "\n",
    "    res = np.zeros(len(hit_times), dtype=pseudo_hitlet_dtype())\n",
    "    res['time'] = hit_times\n",
    "    res['length'] = 1\n",
    "    res['dt'] = 1\n",
    "    res['area'] = ak.to_numpy(ak.ravel(pmthits['pmthitCharge']))\n",
    "    res['channel'] = ak.to_numpy(ak.ravel(pmthits['pmthitID']))\n",
    "\n",
    "    #mc_truth = get_mc_truth(pmthits, res)\n",
    "\n",
    "\n",
    "    #Cut all hits which are more delayed than max time after the \n",
    "    # last event:\n",
    "    # TODO: This is not 100 % correct as we need to do this actually\n",
    "    # for ecah individual event....\n",
    "    mask = (res['time'] - event_times.max())/10**9 < max_time\n",
    "    res = np.sort(res[mask], order=('time', 'channel'))\n",
    "    print(len(res))\n",
    "    res = stack_hitlets(res)\n",
    "    print(len(res))\n",
    "    \"\"\"\n",
    "    if len(mc_truth):\n",
    "        mc_truth = np.sort(mc_truth[mask], order=('time', 'channel'))\n",
    "        mc_truth = stack_truth(mc_truth) \"\"\"\n",
    "    return res\n",
    "\n",
    "\n",
    "import cutax\n",
    "def convert_to_events(pseudo_hitlets):\n",
    "\n",
    "    st_pseudo = cutax.contexts.xenonnt_online()\n",
    "    p_events = st_pseudo.get_single_plugin('0', 'events_nv')\n",
    "    # Events are only sorted by time within each file! \n",
    "    # Multiple files overlap in time!\n",
    "    pseudo_events = []\n",
    "    pseudo_event_positions = []\n",
    "    pseudo_center_time_cut = []\n",
    "    last_time_seen = None\n",
    "    _pseudo_hitlets=pseudo_hitlets\n",
    "    if last_time_seen:\n",
    "        time_offset = last_time_seen - _pseudo_hitlets['time'].min()\n",
    "        _pseudo_hitlets['time'] += time_offset + 2000\n",
    "    \n",
    "    last_time_seen = _pseudo_hitlets['time'].max()\n",
    "    _pseudo_events = p_events.compute(_pseudo_hitlets, 0, _pseudo_hitlets['time'].max()+10)\n",
    "    pseudo_events.append(_pseudo_events)\n",
    "\n",
    "    pseudo_events = np.concatenate(pseudo_events)\n",
    "    return pseudo_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2bf8b-dcb3-44f6-be11-2f2afd5f5635",
   "metadata": {},
   "source": [
    "# Running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18386c1c-132e-4314-9205-0eb8cfefd5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "quantum_efficiency = _init_quantum_efficiency()\n",
    "\n",
    "data=[]\n",
    "ce = 0.75 # value from SR0 AmBe data-MC matching\n",
    "print(\"Collection_Efficiency:\",ce)\n",
    "\n",
    "#Leggo i file root (output G4) e li appendo ad un singolo array\n",
    "for i in range(0,100):\n",
    "    file_root = f'/mnt/xedisk01/amancuso/AmBesim/nT_mc_tutcw5p9m_000{i:02}.root'\n",
    "    #print(\"Opening File :\",file_root)\n",
    "    root_file = uproot.open(file_root)\n",
    "    root_data = root_file['events'].arrays(['eventid', 'pmthitTime', 'pmthitEnergy', 'pmthitID'])\n",
    "    data.append(root_data)\n",
    "    \n",
    "# trasformo data in awkward \n",
    "pmthits = ak.concatenate(data)\n",
    "#Taglio PMT nVeto\n",
    "cut_nveto_data(pmthits)\n",
    "# Conversione Energia in lambda\n",
    "convert_energy_to_wavelength(pmthits)\n",
    "n_photons_wo_qe = ak.sum(ak.num(pmthits['pmthitTime'], axis=1))\n",
    "n_events_wo_qe = len(pmthits)\n",
    "#Prima di applicare la QE ho :\n",
    "print(f'Number of events w/o QE: {n_events_wo_qe}')\n",
    "print(f'Number of photons w/o QE: {n_photons_wo_qe}')\n",
    "\n",
    "#QE and CE Manipulation (ma anche Acceptance) \n",
    "# Appiattisco l'array e applico i tagli (per velocizzare). Dopo uso offset per ricostruire la struttura originaria.\n",
    "offsets = ak.num(pmthits['pmthitWavelength'])\n",
    "pmthitchannel = ak.ravel(pmthits['pmthitID'])\n",
    "pmthitwavelengths = ak.ravel(pmthits['pmthitWavelength'])\n",
    "buffer = np.zeros(len(pmthitwavelengths), np.int16)\n",
    "\n",
    "for ch in range(2000, 2120):\n",
    "    mask = pmthitchannel == ch\n",
    "    qe = quantum_efficiency[str(ch)](pmthitwavelengths[mask])\n",
    "    p_detected = np.random.binomial(1, qe*ce*spe_acc[ch-2000])\n",
    "    buffer[mask] = p_detected\n",
    "#Buffer -> detection probability 0-1\n",
    "pmthits['pmthitCharge'] = ak.unflatten(buffer, offsets)\n",
    "_photons_detected = pmthits['pmthitCharge'] == 1\n",
    "#Tolgo gli hit che non sono stati rivelati\n",
    "pmthits[\"pmthitCharge\"]=pmthits[\"pmthitCharge\"][_photons_detected]\n",
    "pmthits[\"pmthitWavelength\"]=pmthits[\"pmthitWavelength\"][_photons_detected]\n",
    "pmthits[\"pmthitID\"]=pmthits[\"pmthitID\"][_photons_detected]\n",
    "pmthits[\"pmthitTime\"]=pmthits[\"pmthitTime\"][_photons_detected]\n",
    "\n",
    "n_photons_w_qe = ak.sum(ak.num(pmthits['pmthitTime'], axis=1))  #Calcolo il numero di hits sopravvissuti (numero di entries per ogni riga, sommati)\n",
    "n_events_w_qe = len(pmthits) #Calcolo il numero di eventi (numero di righe)\n",
    "\n",
    "print(f'Number of events w/ QE: {n_events_w_qe}')\n",
    "print(f'Number of photons w/ QE: {n_photons_w_qe}')\n",
    "\n",
    "#Campionamento della carica\n",
    "#Charge sampling.\n",
    "#pmthits = _get_charge(pmthits,y_cdfs) \n",
    "pmthits = _get_charge(pmthits,pdf_per_channel,x_interp)\n",
    "\n",
    "\n",
    "n_photons_recorded = ak.sum(ak.num(pmthits['pmthitTime'][pmthits['pmthitCharge'] > 0], axis=1))\n",
    "n_events_recorded = len(pmthits)\n",
    "print(f'Number of events recorded: {n_events_recorded}')\n",
    "print(f'Number of photons recorded: {n_photons_recorded}') \n",
    "# Carica a 0 registrata in alcuni hits.\n",
    "\n",
    "#*----------------Creo Hitlets e Events --------------*\n",
    "hitlets = convert_to_hitlets(pmthits)\n",
    "events = convert_to_events(hitlets)\n",
    "np.save(f'./events/events_Andrea_{ce}.npy', events)\n",
    "np.save(f'./hitlets/hitlets_Andrea_{ce}.npy', hitlets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
