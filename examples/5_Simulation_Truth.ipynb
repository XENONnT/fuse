{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Truth\n",
    "\n",
    "This notebook will introduce you to the concept of simulation truth in fuse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Simulation Context\n",
    "\n",
    "Similar to the previous notebooks, we will start by importing the necessary modules and creating a simulation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = fuse.context.full_chain_context(output_folder=\"./fuse_data\")\n",
    "\n",
    "st.set_config(\n",
    "    {\n",
    "        \"path\": \"/project2/lgrandi/xenonnt/simulations/testing\",\n",
    "        \"file_name\": \"pmt_neutrons_100.root\",\n",
    "        \"entry_stop\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "run_number = \"00000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw_Records and Contributing_Clusters\n",
    "\n",
    "First we will run the simulation up to `raw_records`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.make(run_number, \"microphysics_summary\")\n",
    "st.make(run_number, \"photon_summary\")\n",
    "st.make(run_number, \"raw_records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the main simulation output is produced, we can build some truth information. First we will build `records_truth`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.make(run_number, \"records_truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `raw_records`and `records_truth` are of the same data_kind and can be loaded together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_records = st.get_array(run_number, [\"raw_records\", \"records_truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`contributing_clusters` gives you five additional columns. These are:\n",
    "- `s1_photons_in_record` - The number of S1 photons in the `raw_record`\n",
    "- `s2_photons_in_record` - The number of S2 photons in the `raw_record`\n",
    "- `ap_photons_in_record` - The number of (virtual) PMT afterpulse 'photons' in the record\n",
    "- `raw_area` - The sum of the contributing photon gains divided by the gain of the PMT\n",
    "\n",
    "Lets have a look on the number of photons that make it into the first record: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(\"S1 photons:\", raw_records[index][\"s1_photons_in_record\"])\n",
    "print(\"S2 photons:\", raw_records[index][\"s2_photons_in_record\"])\n",
    "print(\"AP photons:\", raw_records[index][\"ap_photons_in_record\"])\n",
    "print(\"Raw area:\", raw_records[index][\"raw_area\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peaks and peak_truth\n",
    "\n",
    "Next we can process the simulation result to `peak_basics`. Strax(en) will merge multiple records into a peak. The PeakTruth plugin will evaluate which photons contribute to a peak and calculate a truth output for each peak. The provided columns for each peak are:\n",
    "- `s1_photons_in_peak` - The number of S1 photons that contributed to the peak\n",
    "- `s2_photons_in_peak` - The number of S2 photons that contributed to the peak\n",
    "- `ap_photons_in_peak` - The number of (virtual) PMT afterpulse 'photons' that contributed to the peak\n",
    "- `raw_area_truth` - The sum of all contributing photon gains divided by the gains of the PMTs\n",
    "- `observable_energy_truth` - Estimate of the energy that is associated with the peak.\n",
    "- `number_of_contributing_clusters_s1` - Number of clusters that contributed to the peak with S1 photons\n",
    "- `number_of_contributing_clusters_s2` - Number of clusters that contributed to the peak with S2 photons\n",
    "- `average_x_of_contributing_clusters` - Weighted average of the x position of the clusters that contributed to the peak\n",
    "- `average_y_of_contributing_clusters` - Weighted average of the y position of the clusters that contributed to the peak\n",
    "- `average_z_of_contributing_clusters` - Weighted average of the z position of the clusters that contributed to the peak\n",
    "- `average_x_obs_of_contributing_clusters` - Weighted average of the observed x position of the clusters that contributed to the peak\n",
    "- `average_y_obs_of_contributing_clusters` - Weighted average of the observed y position of the clusters that contributed to the peak\n",
    "- `average_z_obs_of_contributing_clusters` - Weighted average of the observed z position of the clusters that contributed to the peak\n",
    "\n",
    "Lets take a closer look at `observable_energy_truth` using an example: \n",
    "If we would have two clusters, the first one with 100 keV energy producig 100 S1 photons and the second one with 10 keV producing 10 S1 photons. After simulation and processing we find two S1 peaks in our data. The first S1 consitis of 90 photons from the first cluster and 5 photons of the second cluster. The `observable_energy_truth` for this peak is calculated as: 90/100 * 100 keV + 5/10 * 10 keV = 90 keV + 5 keV = 95 keV. The second S1 consists of 3 photons from the first cluster and 4 photons of the second cluster. The `observable_energy_truth` for this peak is calculated as: 3/100 * 100 keV + 4/10 * 10 keV = 3 keV + 4 keV = 7 keV. A similar calculation is done for the S2 peaks but replacing the S1 photons with the S2 photons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.make(run_number, \"peak_positions\")\n",
    "st.make(run_number, \"peak_truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As strax(en) will take care of the matching of our truth information to the individual peaks, we can simply load the `peak_basics` and `peak_truth` data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_basics = st.get_df(run_number, [\"peak_basics\", \"peak_truth\", \"peak_positions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a peak area bias study we could now compare the raw_area to the peak area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_basics[[\"area\", \"raw_area_truth\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also be interested in the peak classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_basics[[\"type\", \"s1_photons_in_peak\", \"s2_photons_in_peak\", \"ap_photons_in_peak\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you might want to check how our position reconstruction is doing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_basics[\n",
    "    [\n",
    "        \"type\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"average_x_obs_of_contributing_clusters\",\n",
    "        \"average_y_obs_of_contributing_clusters\",\n",
    "        \"average_z_obs_of_contributing_clusters\",\n",
    "    ]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surviving Clusters\n",
    "Next lets evaluate if an energy deposit makes it into a peak. This is done by the `SurvivingClusters` plugin. It will provide the following columns:\n",
    "- `creating_a_photon` - Boolean if the cluster created a propagated photon\n",
    "- `in_a_peak` - Boolean if the cluster is in a peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.make(run_number, \"surviving_clusters\")\n",
    "microphysics_summary = st.get_df(run_number, [\"microphysics_summary\", \"surviving_clusters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded we could have a look at clusters that did not make it into a peak: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microphysics_summary.query(\"in_a_peak == False\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Truth\n",
    "\n",
    "Lets move from the peak level to event level data. This is done by the `EventTruth` plugin. It will provide the following columns:\n",
    "- `x_obs_truth` - The x position of the event. This corresponds to the x position of the main S2.\n",
    "- `y_obs_truth` - The y position of the event. This corresponds to the y position of the main S2.\n",
    "- `z_obs_truth` - The z position of the event. This is calculated as mean of the main S1 and S2 `average_z_obs_of_contributing_clusters`. Does this make sense?\n",
    "- `energy_of_main_peaks_truth` - This is intended to be the energy that can be found in the main S1 and S2. It is calculated as the mean of the `observable_energy_truth` of the main S1 and S2. Does this make any sense???\n",
    "- `total_energy_in_event_truth` - The sum of all energy deposits that are in the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.make(run_number, \"event_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data = st.get_df(run_number, [\"event_info\", \"event_truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets take a look at the energy informations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data[[\"e_ces\", \"energy_of_main_peaks_truth\", \"total_energy_in_event_truth\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the positions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data[[\"x\", \"x_obs_truth\", \"z\", \"z_obs_truth\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Tagging\n",
    "\n",
    "Finally we can investigate if a cluster contributed to the main or alternative S1 or S2. This is done by the `ClusterTagging` plugin. It will provide the following columns:\n",
    "- `in_main_s1` - Boolean if the cluster contributed to the main S1\n",
    "- `in_main_s2` - Boolean if the cluster contributed to the main S2\n",
    "- `in_alt_s1` - Boolean if the cluster contributed to an alternative S1\n",
    "- `in_alt_s2` - Boolean if the cluster contributed to an alternative S2\n",
    "- `photons_in_main_s1` - Number of photons the cluster contributed to the main S1\n",
    "- `photons_in_main_s2` - Number of photons the cluster contributed to the main S2\n",
    "- `photons_in_alt_s1` - Number of photons the cluster contributed to the alternative S1\n",
    "- `photons_in_alt_s2` - Number of photons the cluster contributed to the alternative S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.make(run_number, \"tagged_clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load it together with e.g. microphysics_summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_with_tagged_clusters = st.get_df(\n",
    "    run_number, [\"microphysics_summary\", \"tagged_clusters\", \"s2_photons_sum\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at some cluster information that contributed to the main S2 of the second event: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_with_tagged_clusters_cut = ms_with_tagged_clusters.query(\"eventid == 1 & in_main_s2 == True\")\n",
    "ms_with_tagged_clusters_cut[[\"ed\", \"sum_s2_photons\", \"photons_in_main_s2\"]].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
